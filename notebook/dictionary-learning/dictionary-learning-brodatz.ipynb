{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path += ['..', '../..']\n",
    "from modules.dictionary_learning.spd_dictionary_learning import AffineConstrainedSPDDLSC as DL\n",
    "from modules.feature_extraction.image import extract_patches_2d, reconstruct_from_patches_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "patch_size = (32, 32)\n",
    "extraction_step = patch_size\n",
    "n_components = 10\n",
    "eps = 1e-16\n",
    "\n",
    "path = '../../data/brodatz'\n",
    "imgs = [cv2.imread(os.path.join(path, f'D{i}.png'), False) for i in range(2, 11)]\n",
    "\n",
    "patches = [extract_patches_2d(img, patch_size, extraction_step).astype(np.float) for img in imgs]\n",
    "length, half_length = len(patches[0]), len(patches[0]) // 2\n",
    "shuffled_indices = list(range(length))\n",
    "random.shuffle(shuffled_indices)\n",
    "\n",
    "train_patches = np.vstack([patch[shuffled_indices[:half_length]] for patch in patches])\n",
    "test_patches = np.vstack([patch[shuffled_indices[half_length:]] for patch in patches])\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(imgs[0], cmap='gray')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(imgs[1], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary Learning\n",
    "\n",
    "$$\\mathop{\\rm{minimize}}_{\\mathcal{D}, W}\\ \\frac{1}{2}\\sum_{i=1}^n\\left\\|\\sum_{j=1}^mw_{ij}\\log_{x_i}(a_j)\\right\\|_{x_i}^2 + \\lambda\\|W\\|_1\\quad\n",
    "\\text{subject to}\\ a_j \\in \\mathcal{P}(r),\\ \\sum_{j=1}^m w_{ij} = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "from typing import List\n",
    "\n",
    "def extract_feature(patches: np.ndarray, eps: float=1e-8):\n",
    "    n_patches, p_h, p_w = patches.shape\n",
    "    res = np.empty((n_patches, p_h * p_w, 5))\n",
    "    kernel_x = np.array([[0,0,0],[-1,0,1],[0,0,0]])\n",
    "    kernel_y = np.array([[0,-1,0],[0,0,0],[0,1,0]])\n",
    "    kernel_xx = np.array([[0,0,0],[-1,2,-1],[0,0,0]])\n",
    "    kernel_yy = np.array([[0,-1,0],[0,2,0],[0,-1,0]])\n",
    "\n",
    "    res[:,:,1] = np.vstack([np.abs(cv2.filter2D(p, cv2.CV_64F, kernel_x)) for p in patches]).reshape(-1, p_h * p_w)\n",
    "    res[:,:,2] = np.vstack([np.abs(cv2.filter2D(p, cv2.CV_64F, kernel_y)) for p in patches]).reshape(-1, p_h * p_w)\n",
    "    res[:,:,3] = np.vstack([np.abs(cv2.filter2D(p, cv2.CV_64F, kernel_xx)) for p in patches]).reshape(-1, p_h * p_w)\n",
    "    res[:,:,4] = np.vstack([np.abs(cv2.filter2D(p, cv2.CV_64F, kernel_yy)) for p in patches]).reshape(-1, p_h * p_w)\n",
    "    res[:,:,0] = patches.reshape(-1, p_h * p_w)\n",
    "    return np.array([np.cov(x, rowvar=False) + np.eye(5) * eps for x in res])\n",
    "\n",
    "train_feature = extract_feature(train_patches)\n",
    "test_feature = extract_feature(test_patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symmetrix Positive Definite Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "max_iter = 5\n",
    "dl = DL(\n",
    "    n_components = n_components ** 2,\n",
    "    max_iter = max_iter,\n",
    "    extended_output = True,\n",
    "    initial_step = 1,\n",
    "    armijo_param = 1e-4,\n",
    "    max_iter_dl = 10,\n",
    "    rho = 1e-4,\n",
    "    tau = len(train_feature),\n",
    "    max_iter_sp = 1000\n",
    ")\n",
    "\n",
    "dl.fit(train_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(dl.f)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time train_transformed = dl.transform(train_feature)\n",
    "%time test_transformed = dl.transform(test_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symmetric Positive Definite Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "label = np.hstack([[i]*half_length for i in range(len(imgs))]).astype(np.float)\n",
    "clf = SVC(C=1e2, gamma='auto', random_state=0)\n",
    "clf.fit(train_transformed, label)\n",
    "predicted = clf.predict(test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(confusion_matrix(label, predicted), square=True, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.diag(confusion_matrix(label, predicted))) / len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
